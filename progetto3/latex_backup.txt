\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[a4paper, top=30mm, bottom=30mm, left=20mm, right=20mm]{geometry}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{soul}
\usepackage{cite}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{subcaption}
\usepackage{pythonhighlight}
\usepackage{graphicx}
\newcommand{\pyobject}[1]{\ovalbox{\color{red}{\texttt{#1}}}}
\title{\Huge Project 3 of "Metodi Del Calcolo Scientifico" \\ \Large Academic Year 2019/2020}
\author{Simone Paolo Mottadelli, 820786}

\date{}
\begin{document}
\maketitle
\newpage
\tableofcontents
\newpage
\large
\section{Introduction}
\label{sec:introduction}
The main purpose of this project was to implement different solvers of systems of linear equations and organize them into a library. In particular, the following iterative solvers had to be implemented, limiting to the case of symmetric and positive definite matrices:
\begin{itemize}
    \item The Jacobi method;
    \item The Gauß-Seidel method;
    \item the Gradient method;
    \item the Conjugate Gradient method.
\end{itemize}
This document consists of two sections: Section \ref{sec:implementation} describes how the library has been implemented, while Section \ref{sec:experimentation} describes the validation study that has been conducted with the developed library.
\section{Implementation}
\label{sec:implementation}
The required library has been implemented using the \textbf{Python} \cite{van1995python} programming language because it is open source, very powerful and it provides all the functionalities and libraries needed to achieve the goals of the project. In particular, the following libraries have been exploited: 
\begin{itemize}
    \item \textbf{NumPy} \cite{numpy}, which is the core library for scientific computing in Python \cite{van1995python}, which mainly adds support for dense multidimensional arrays. In particular, it provides the \textit{ones()} and the \textit{zeros()} functions to generate a vector with all the entries equal to 1 or to 0, respectively;
    \item \textbf{SciPy} \cite{2020SciPy-NMeth}, which is a Python-based ecosystem of open-source software for mathematics, science and engineering, which also adds support for sparse matrices.
\end{itemize}
In order to improve the readability of the code and, thus, its maintainability, the sofware has been organized into the following modules and classes:
\begin{itemize}
    \item \textbf{main.py}, which is the entry point of the program and which controls the execution flow of the program;
    \item \textbf{input\_parser.py}, which implements the logic for validating the user input in the \textit{InputParser} class;
    \item \textbf{mtx\_file\_reader.py}, which contains the \textit{MTXFileReader} class, whose purpose is to implement the logic for loading the matrix in input from an .mtx file and store it in memory;
    \item \textbf{iterative\_solver\_comparator.py}, containing the \textit{IterativeSolverComparator} class, which is responsible for comparing the four aforementioned solvers in terms of their execution time, relative error and number of iterations.
    \item \textbf{abstract\_iterative\_solver.py}, which contains the \textit{AbstractIterativeSolver} class, which is the template for all the iterative solvers of the library, i.e., it implements the logic of a general iterative solver;
    \item \textbf{jacobi\_solver.py}, containing the \textit{JacobiSolver} class, which realizes the logic for updating the approximate solution based on the Jacobi updating strategy;
    \item \textbf{gauss\_seidel\_solver.py}, containing the \textit{GaussSeidelSolver} class, which implements the logic for updating the approximate solution based on the Gauß-Seidel updating strategy;
    \item \textbf{gradient\_solver.py}, containing the \textit{GradientSolver} class, which realizes the logic for updating the approximate solution based on the Gradient updating strategy;
    \item \textbf{conjugate\_gradient\_solver.py}, containing the \textit{ConjugateGradientSolver} class, which realizes the logic for updating the approximate solution based on the Conjugate Gradient updating strategy;
\end{itemize}
From an architectural point of view, Figure \ref{fig:uml_class_diagram} shows the structure of the project through a \textbf{UML} \cite{UML} diagram. It is a simple diagram showing both the dependencies between the software components and the attributes and methods of each class at a high level of abstraction. Infact, every software class is modelled as a rectangle: on top there is the name of the class, in the middle there are the attributes of the class, each specified by a data type, and on the bottom there are the signatures of its methods. The links between the rectangles model the relationships between the software components: a class can use another class in its implementation or a class can extend another class. Note that the \textit{main.py} module is just a simple script that implements the entry point of the program and that controls the execution flow of the program. This is why it has not been modelled as a class rectangle.
\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth]{class_diagram.png}
    \caption{A UML \cite{UML} diagram that shows the structure of the software}
    \label{fig:uml_class_diagram}
\end{figure}\\
More in detail, as it is shown in the UML diagram and in Figure \ref{fig:main.py}, the \textit{main.py} module uses the \textit{InputParser} class to parse and validate the user input, that is, it checks whether the .mtx file exists in the file system. Then, as soon as the user input has been validated, the \textit{main.py} module uses the \textit{MTXFileReader} class to load the matrix from the file system and store it in memory as sparse. Finally, the \textit{main.py} module uses the \textit{IterativeSolverComparator} class to start the comparison between the different solver implementations and to print the results obtained at the end of the comparison.
\newpage
\begin{figure}[h!]
    \centering
    \begin{python}
def main(argv):
    # input validation
    mtx_file = InputParser(argv).parse()

    # matrix extraction from the .mtx file
    tols = [1e-4, 1e-6, 1e-8, 1e-10]
    A = MTXFileReader(mtx_file, tols).load_matrix()

    # launch comparison
    IterativeSolverComparator(A).start_comparison()
    \end{python}
    \caption{Code inside the \textit{main.py} module}
    \label{fig:main.py}
\end{figure}
\begin{figure}[h!]
    \centering
    \begin{python}
class IterativeSolverComparator:
    # Constructor: by using the "self" keyword we can access the attributes 
    # and methods of the class in Python
    def __init__(self, A, tols):
        self.A = A
        self.x_es = ones(A.shape[0]) # A.shape[0] gets the first dimension
        self.b = A.dot(self.x_es)
        self.tols = tols

    # This is a helper method for the start_comparison() method: 
    # it simply prints the results achieved by a solver to the console
    def print_results(self, solver):
        time_start = time()
        x_app, num_iter = solver.solve()
        time_end = time()
        exec_time = "{:.32e}".format(time_end - time_start)
        rel_error = "{:.32e}".format(norm(self.x_es - x_app) / 
                                     norm(self.x_es))
        formatted_tol = "{:.0e}".format(solver.tol)
        solver_name = type(solver).__name__
        print("\n%s results with tolerance = %s:" %
                                     (solver_name, formatted_tol))
        print("Relative error = %s" % rel_error)
        print("Number of iterations = %d" % num_iter)
        print("Execution time = %s\n" % exec_time)

    # This method simply solves the linear systems with the four different  
    # solver to the varying of the tolerance and shows the achieved results 
    # on the console
    def start_comparison(self):
        for tol in self.tols:
            self.print_results(JacobiSolver(self.A, self.b, tol))
            self.print_results(GaussSeidelSolver(self.A, self.b, tol))
            self.print_results(GradientSolver(self.A, self.b, tol))
            self.print_results(ConjugateGradientSolver(self.A, self.b, tol))

    \end{python}
    \caption{Code inside the \textit{IterativeSolverComparator} class}
    \label{fig:comparator.py}
\end{figure}
\newpage
\noindent
As shown in Figure \ref{fig:comparator.py}, when an object of type \textit{IterativeSolverComparator} is instantiated, the \textit{x\_es} vector and the \textit{b} vector are generated: the former has all its entries equals to 1 and it represents the exact solution of the system of equations, while the latter represents the right-hand side coefficients of the system and it is generated by using the \textit{A} matrix in input and the just created \textit{x\_es} vector. Soon afterwards, when the \textit{start\_comparison()} method is called, the \textit{IterativeSolverComparator} class uses all the different solvers to solve the system of equations $Ax = b$ to the varying of the tolerance, which is a value among $[10^{-4}, 10^{-6}, 10^{-8}, 10^{-10}]$, and prints on the screen the relative error, the number of iterations and the execution time needed to generate a solution.
\begin{figure}[h!]
    \centering
    \begin{python}
class AbstractIterativeSolver:

    # Constructor
    def __init__(self, A, b, tol):
        self.A = A
        self.b = b
        self.tol = tol
        self.x = zeros(A.shape[0]) # A.shape[0] gets the first dimension
        self.max_iter = 20000
        self.current_iter = 1
        self.residual = self.compute_residual()

    # Helper method that computes the residual
    def compute_residual(self):
        return self.b - self.A.dot(self.x)

    # Helper method that returns TRUE if the solver must continue to 
    # iterate, FALSE otherwise.
    def must_continue(self):
        if self.current_iter >= self.max_iter:
            print("[WARNING] max number of iterations reached: solver failed to achieve convergence!")
            return False
        return norm(self.residual) / norm(self.b) >= self.tol

    # Template method for a classical iterative method
    def solve(self):
        while self.must_continue():
            self.x = self.update()
            self.residual = self.compute_residual()
            self.current_iter += 1
        return self.x, self.current_iter

    # Method that must be overridden by the subclasses.
    def update(self):
        raise NotImplementedError("This method has not been 
                                        implemented yet")
    \end{python}
    \caption{Implementation of the general iterative solver}
    \label{fig:abstractclass}
\end{figure}
\newpage\noindent
All the solvers extend the \textit{AbstractIterativeSolver} class, thus inheriting all its methods and attributes. The code of such class can be inspected in Figure \ref{fig:abstractclass} and, as it can be seen, the \textit{solve()} method implements the main loop, which stops if either the maximum number of iterations is reached or the scaled residual is less than the tolerance. At each iteration of the main loop, the \textit{update()} method updates the approximate solution, but, since the update strategy strictly depends on the specific solving method (e.g., the Jacobi method), the \textit{update()} method is abstract. More in detail, an abstract method is such that all the iterative solvers that extend the \textit{AbstractIterativeSolver} class must override it, providing an implementation of such method (abstract methods are analogous to the concept of virtual methods in the \textit{C++} \cite{c++} programming language). With this design pattern, implementing the solvers is a trivial task, since they only have to extend the \textit{AbstractIterativeSolver} class and implement the \textit{update()} method.
\begin{figure}[h!]
    \centering
    \begin{python}
class JacobiSolver(AbstractIterativeSolver):

    # Constructor
    def __init__(self, A, b, tol):
        super().__init__(A, b, tol)
        self.P_inv = csr_matrix(identity(A.shape[0]) / A.diagonal())

    # This function implements the update strategy of the Jacobi method
    def update(self):
        return self.x + self.P_inv.dot(self.residual)
    \end{python}
    \caption{Implementation of the Jacobi method}
    \label{fig:jacobi}
\end{figure}\\
For instance, Figure \ref{fig:jacobi} shows the implementation of the Jacobi method, which consists of just the \textit{update()} method. It's worthwhile to notice that the inverse of the P matrix is computed only once inside the constructor, where the P matrix is the diagonal matrix resulting from the factorization of the A matrix.\\
Figure \ref{fig:gaussseidel} shows the implementation of the Gauß-Seidel method. Note that also in this case, for matters of efficiency, the P lower triangular matrix is computed just once using the \textit{tril()} function provided by the SciPy \cite{2020SciPy-NMeth} library. In addition, the \textit{spsolve\_triangular()} method, also provided by the SciPy \cite{2020SciPy-NMeth} library, has been used to efficiently solve the system of equations where P is the coefficient matrix and the residual vector is the right-hand side of the system.\\
Lastly, Figure \ref{fig:conjugategradient} and Figure \ref{fig:gradient} show the code used to implement the Gradient solver and the Conjugate Gradient solver, respectively. In order to improve the maintainability of the code, the \textit{compute\_alpha()} and the \textit{compute\_beta()} helper methods have been implemented.
\newpage
\begin{figure}[h!]
    \centering
    \begin{python}
class GaussSeidelSolver(AbstractIterativeSolver):

    # Constructor
    def __init__(self, A, b, tol):
        super().__init__(A, b, tol)
        self.P = tril(self.A, format="csr")

    # This method simply computes the next vector solution x
    def update(self):
        return self.x + spsolve_triangular(self.P, self.residual)
    \end{python}
    \caption{Implementation of the Gauß-Seidel method}
    \label{fig:gaussseidel}
\end{figure}
\begin{figure}[h!]
    \centering
    \begin{python}
class ConjugateGradientSolver(AbstractIterativeSolver):

    # Constructor
    def __init__(self, A, b, tol):
        super().__init__(A, b, tol)
        self.d_k = self.residual

    # This method computes the next vector solution x based on the Conjugate
    # Gradient update strategy
    def update(self):
        y_k = self.A.dot(self.d_k)
        alpha = self.compute_alpha(y_k)
        self.x = self.x + alpha * self.d_k
        self.residual = self.compute_residual()
        beta = self.compute_beta(y_k)
        self.d_k = self.residual - beta * self.d_k
        return self.x

    # This is a helper function for the update() method and simply computes
    # the value of "alpha"
    def compute_alpha(self, y_k):
        alpha_numerator = self.d_k.dot(self.residual)
        alpha_denominator = self.d_k.dot(y_k)
        return alpha_numerator / alpha_denominator

    # This is a helper function for the update() method and simply computes
    # the value of "beta"
    def compute_beta(self, y_k):
        beta_numerator = self.d_k.dot(self.A.dot(self.residual))
        beta_denominator = self.d_k.dot(y_k)
        return beta_numerator / beta_denominator
    \end{python}
    \caption{Implementation of the Conjugate Gradient method}
    \label{fig:conjugategradient}
\end{figure}
\newpage
\begin{figure}[h!]
    \centering
    \begin{python}
class GradientSolver(AbstractIterativeSolver):

    # This method computes the next x vector solution using the Gradient
    # update strategy
    def update(self):
        alpha = self.compute_alpha()
        return self.x + alpha * self.residual

    # This is a helper function for the update() method and simply computes
    # the value of "alpha"
    def compute_alpha(self):
        alpha_numerator = self.residual.dot(self.residual)
        alpha_denominator = self.residual.dot(self.A.dot(self.residual))
        return alpha_numerator / alpha_denominator
    \end{python}
    \caption{Implementation of the Gradient method}
    \label{fig:gradient}
\end{figure}
\noindent
In conclusion, from a practical point of view, to launch this program it is sufficient to execute the following command on a command prompt window (e.g., Windows PowerShell, Linux Bash, et cetera):
\begin{lstlisting}[basicstyle=\small\centering]
> python main.py <filepath>
\end{lstlisting}
For example, to launch it on the matrix saved in \textit{my\_file.mtx}, it is sufficient to execute the following command:
\begin{lstlisting}[basicstyle=\small\centering]
> python main.py my_file.mtx
\end{lstlisting}
For further details on the implementation of this library, all the code is available at: \url{https://github.com/SimoneMottadelli/MetodiDelCalcoloScientifico}.\\
\section{Validation study}
\label{sec:experimentation}

\newpage
\bibliography{references}
\bibliographystyle{unsrt}
\end{document}